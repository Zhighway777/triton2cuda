import os
import sys
import tempfile
import torch
import importlib.util
import subprocess
import time
import argparse
from typing import Tuple, List, Dict, Any
from enum import Enum
import traceback
import requests
from datetime import datetime
import json

# é”™è¯¯ç±»å‹æšä¸¾
class ErrorType(Enum):
    RUNTIME_ERROR = "RuntimeError"
    COMPILATION_ERROR = "CompilationError"
    OUTPUT_MISMATCH_ERROR = "OutputMismatchError"
    NETWORK_ERROR = "NetworkError"        # æ–°å¢ï¼šAPIè¿æ¥ç›¸å…³é”™è¯¯
    API_ERROR = "APIError"               # æ–°å¢ï¼šAPIè°ƒç”¨é”™è¯¯
    SUCCESS = "Success"

class APICallMonitor:
    """APIè°ƒç”¨ç›‘æ§ç±»"""
    
    def __init__(self):
        self.call_history = []
        self.current_call = None
    
    def start_call(self, model_type: str, prompt_type: str, triton_code_length: int):
        """å¼€å§‹ç›‘æ§APIè°ƒç”¨"""
        self.current_call = {
            "model_type": model_type,
            "prompt_type": prompt_type,
            "triton_code_length": triton_code_length,
            "start_time": datetime.now(),
            "start_timestamp": time.time(),
            "request_details": {},
            "response_details": {},
            "error_details": {},
            "success": False,
            "duration": 0
        }
    
    def record_request(self, **kwargs):
        """è®°å½•è¯·æ±‚è¯¦æƒ…"""
        if self.current_call:
            self.current_call["request_details"].update(kwargs)
    
    def record_response(self, **kwargs):
        """è®°å½•å“åº”è¯¦æƒ…"""
        if self.current_call:
            self.current_call["response_details"].update(kwargs)
    
    def record_error(self, error_type: str, error_message: str, full_traceback: str = None):
        """è®°å½•é”™è¯¯è¯¦æƒ…"""
        if self.current_call:
            self.current_call["error_details"] = {
                "error_type": error_type,
                "error_message": error_message,
                "full_traceback": full_traceback,
                "timestamp": datetime.now().isoformat()
            }
    
    def end_call(self, success: bool, response_content: str = None):
        """ç»“æŸAPIè°ƒç”¨ç›‘æ§"""
        if self.current_call:
            self.current_call["success"] = success
            self.current_call["duration"] = time.time() - self.current_call["start_timestamp"]
            self.current_call["end_time"] = datetime.now()
            
            if response_content:
                self.current_call["response_details"]["content_length"] = len(response_content)
                self.current_call["response_details"]["has_code_block"] = "```" in response_content
            
            self.call_history.append(self.current_call.copy())
            self.current_call = None
    
    def get_summary(self):
        """è·å–è°ƒç”¨æ‘˜è¦"""
        total_calls = len(self.call_history)
        successful_calls = sum(1 for call in self.call_history if call["success"])
        total_duration = sum(call["duration"] for call in self.call_history)
        
        return {
            "total_calls": total_calls,
            "successful_calls": successful_calls,
            "failed_calls": total_calls - successful_calls,
            "total_duration": total_duration,
            "average_duration": total_duration / total_calls if total_calls > 0 else 0,
            "success_rate": successful_calls / total_calls if total_calls > 0 else 0
        }

class NetworkMonitor:
    """APIè¿é€šæ€§ç›‘æ§ç±»"""
    
    @staticmethod
    def check_api_endpoints():
        """æ£€æŸ¥APIç«¯ç‚¹å¯ç”¨æ€§"""
        endpoints = {
            "æ™ºè°±AI": "https://open.bigmodel.cn/api/paas/v4/chat/completions",
            "OpenRouter": "https://openrouter.ai/api/v1/chat/completions",
            "DeepSeek": "https://api.deepseek.com/v1/chat/completions"
        }
        
        results = {}
        for name, url in endpoints.items():
            try:
                # åªæ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å¯è¾¾ï¼Œä¸å‘é€å®é™…è¯·æ±‚
                response = requests.head(url, timeout=10)
                results[name] = {
                    "available": response.status_code != 404,
                    "status_code": response.status_code,
                    "response_time": response.elapsed.total_seconds()
                }
            except Exception as e:
                results[name] = {
                    "available": False,
                    "error": str(e)
                }
        
        return results

class TestResult:
    def __init__(self, file_name: str):
        self.file_name = file_name
        self.error_type = ErrorType.SUCCESS
        self.error_message = ""
        self.compilation_score = 0  # 0 or 1
        self.accuracy_score = 0     # 0-9
        self.total_score = 0        # 0-10
        self.test_details = []      # æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹çš„è¯¦ç»†ä¿¡æ¯
        self.cuda_code = ""         # ç”Ÿæˆçš„CUDAä»£ç 
        self.compilation_output = ""  # ç¼–è¯‘å™¨è¾“å‡º
        self.conversion_details = []  # è½¬æ¢è¿‡ç¨‹è¯¦æƒ…
        self.api_call_history = []  # APIè°ƒç”¨å†å²
        
    def set_error(self, error_type: ErrorType, message: str):
        self.error_type = error_type
        self.error_message = message
        
    def set_compilation_result(self, success: bool, output: str = ""):
        self.compilation_score = 1 if success else 0
        self.compilation_output = output
        
    def set_accuracy_result(self, passed_tests: int, total_tests: int):
        if total_tests > 0:
            self.accuracy_score = int(9 * passed_tests / total_tests)
        else:
            self.accuracy_score = 0
            
    def calculate_total_score(self):
        self.total_score = self.compilation_score + self.accuracy_score
        
    def get_summary(self) -> str:
        return f"{self.file_name}: {self.total_score}/10 (ç¼–è¯‘:{self.compilation_score}/1, å‡†ç¡®æ€§:{self.accuracy_score}/9)"

# ä¿®å¤è·¯å¾„é—®é¢˜
current_file_dir = os.path.dirname(os.path.abspath(__file__))
folder_path = os.path.dirname(current_file_dir)
original_cwd = os.getcwd()
os.chdir(folder_path)

sys.path.append(folder_path)
sys.path.append(os.path.join(folder_path, "example_submission"))
sys.path.append(os.path.join(folder_path, "data", "ref"))

TEST_NN_MODEL_NAME = 'ModelNew'

from tri2cu import triton2cuda

def get_inputs_for_file(file_name):
    """ä¸ºä¸åŒçš„æ–‡ä»¶æä¾›ç›¸åº”çš„è¾“å…¥æ•°æ®"""
    if file_name == "vecadd.py":
        return [
            [torch.randn(1024, device='cuda', dtype=torch.float32), torch.randn(1024, device='cuda', dtype=torch.float32)],
            [torch.randn(8432, device='cuda', dtype=torch.float32), torch.randn(8432, device='cuda', dtype=torch.float32)]
        ]
    elif file_name in ["constant_add.py", "constant_add_block.py"]:
        return [
            [torch.randn(1024, device='cuda', dtype=torch.float32)],
            [torch.randn(200, device='cuda', dtype=torch.float32)]
        ]
    elif file_name in ["outer_vecadd.py", "outer_vecadd_block.py"]:
        return [
            [torch.randn(32, device='cuda', dtype=torch.float32), torch.randn(32, device='cuda', dtype=torch.float32)],
            [torch.randn(100, device='cuda', dtype=torch.float32), torch.randn(90, device='cuda', dtype=torch.float32)]
        ]
    elif file_name in ["longsum.py", "longsoftmax.py", "softmax.py"]:
        return [
            [torch.randn(4, 200, device='cuda', dtype=torch.float32)],
            [torch.randn(8, 128, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "conv2d.py":
        return [
            [torch.randn(4, 8, 8, device='cuda', dtype=torch.float32), torch.randn(4, 4, device='cuda', dtype=torch.float32)],
            [torch.randn(2, 6, 6, device='cuda', dtype=torch.float32), torch.randn(3, 3, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "flashatt.py":
        return [
            [torch.randn(200, device='cuda', dtype=torch.float32), torch.randn(200, device='cuda', dtype=torch.float32), torch.randn(200, device='cuda', dtype=torch.float32)],
            [torch.randn(128, device='cuda', dtype=torch.float32), torch.randn(128, device='cuda', dtype=torch.float32), torch.randn(128, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "matmul.py":
        return [
            [torch.randn(4, 32, 32, device='cuda', dtype=torch.float32), torch.randn(4, 32, 32, device='cuda', dtype=torch.float32)],
            [torch.randn(2, 16, 24, device='cuda', dtype=torch.float32), torch.randn(2, 24, 20, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "mul_relu_fused_block.py":
        return [
            [torch.randn(100, device='cuda', dtype=torch.float32), torch.randn(90, device='cuda', dtype=torch.float32)],
            [torch.randn(64, device='cuda', dtype=torch.float32), torch.randn(48, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "outer_mul_relu_fused_block.py":
        return [
            [torch.randn(90, 100, device='cuda', dtype=torch.float32), torch.randn(90, device='cuda', dtype=torch.float32), torch.randn(90, 100, device='cuda', dtype=torch.float32)],
            [torch.randn(64, 48, device='cuda', dtype=torch.float32), torch.randn(64, device='cuda', dtype=torch.float32), torch.randn(64, 48, device='cuda', dtype=torch.float32)]
        ]
    elif file_name == "quant_matmul.py":
        return [
            [
                torch.randn(32, 8, device='cuda', dtype=torch.float32),
                torch.randint(0, 15, (32,), device='cuda', dtype=torch.int32),
                torch.randint(0, 15, (32, 8), device='cuda', dtype=torch.int32),
                torch.randn(64, 32, device='cuda', dtype=torch.float32)
            ],
            [
                torch.randn(16, 8, device='cuda', dtype=torch.float32),
                torch.randint(0, 15, (16,), device='cuda', dtype=torch.int32),
                torch.randint(0, 15, (16, 8), device='cuda', dtype=torch.int32),
                torch.randn(64, 16, device='cuda', dtype=torch.float32)
            ]
        ]
    else:
        return [
            [torch.randn(1024, device='cuda', dtype=torch.float32)],
            [torch.randn(512, device='cuda', dtype=torch.float32)]
        ]

def get_reference_model_and_inputs(file_name):
    """è·å–å‚è€ƒæ¨¡å‹å’Œè¾“å…¥æ•°æ®"""
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å‚è€ƒå®ç°
    ref_file_path = os.path.join("data", "ref", file_name)
    
    if os.path.exists(ref_file_path):
        module_name = file_name.replace('.py', '_ref')
        spec = importlib.util.spec_from_file_location(module_name, ref_file_path)
        ref_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(ref_module)
        
        RefModel = getattr(ref_module, 'Model', None)
        get_inputs_func = getattr(ref_module, 'get_inputs', None)
        
        if RefModel is None:
            raise ValueError(f"æ— æ³•åœ¨å‚è€ƒå®ç° {file_name} ä¸­æ‰¾åˆ° Model ç±»")
        
        input_tensors = get_inputs_func() if get_inputs_func else get_inputs_for_file(file_name)
        return RefModel, input_tensors
    else:
        # ä½¿ç”¨æœ¬åœ°æµ‹è¯•æ–‡ä»¶ä½œä¸ºå‚è€ƒ
        triton_file_path = os.path.join("data", "triton", "local_test_list", file_name)
        
        if not os.path.exists(triton_file_path):
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ°Tritonæ–‡ä»¶: {triton_file_path}")
        
        module_name = file_name.replace('.py', '_triton')
        spec = importlib.util.spec_from_file_location(module_name, triton_file_path)
        triton_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(triton_module)
        
        TritonModel = getattr(triton_module, 'Model', None)
        if TritonModel is None:
            raise ValueError(f"æ— æ³•åœ¨ {file_name} ä¸­æ‰¾åˆ° Model ç±»")
        
        input_tensors = get_inputs_for_file(file_name)
        return TritonModel, input_tensors

def check_cuda_compilation(cuda_code: str, file_name: str) -> Tuple[bool, str]:
    """æ£€æŸ¥CUDAä»£ç æ˜¯å¦èƒ½å¤Ÿç¼–è¯‘é€šè¿‡"""
    if not cuda_code.strip():
        return False, "ç”Ÿæˆçš„CUDAä»£ç ä¸ºç©º"
    
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•å’Œæ–‡ä»¶
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file = os.path.join(temp_dir, "test_cuda.py")
            with open(temp_file, "w") as f:
                f.write(cuda_code)
            
            # å°è¯•ç”¨Pythonè¯­æ³•æ£€æŸ¥
            try:
                with open(temp_file, "r") as f:
                    compile(f.read(), temp_file, "exec")
                return True, "Pythonè¯­æ³•æ£€æŸ¥é€šè¿‡"
            except SyntaxError as e:
                return False, f"Pythonè¯­æ³•é”™è¯¯: {str(e)}"
            except Exception as e:
                return False, f"Pythonç¼–è¯‘é”™è¯¯: {str(e)}"
                
    except Exception as e:
        return False, f"ç¼–è¯‘æ£€æŸ¥å¤±è´¥: {str(e)}"

def run_cuda_code_test(cuda_code: str, input_tensors: List[List[torch.Tensor]], file_name: str) -> Tuple[List[torch.Tensor], str]:
    """è¿è¡ŒCUDAä»£ç å¹¶è¿”å›ç»“æœ"""
    if not cuda_code.strip():
        raise RuntimeError("ç”Ÿæˆçš„CUDAä»£ç ä¸ºç©º")
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_file = os.path.join(temp_dir, "cuda_code.py")
            with open(temp_file, "w") as f:
                f.write(cuda_code)
            
            # åŠ¨æ€åŠ è½½æ¨¡å—
            spec = importlib.util.spec_from_file_location("cuda_module", temp_file)
            cuda_module = importlib.util.module_from_spec(spec)
            sys.modules["cuda_module"] = cuda_module
            
            try:
                spec.loader.exec_module(cuda_module)
            except Exception as e:
                raise RuntimeError(f"CUDAä»£ç åŠ è½½å¤±è´¥: {str(e)}")
            
            # è·å–ModelNewç±»
            CudaModel = getattr(cuda_module, TEST_NN_MODEL_NAME, None)
            if CudaModel is None:
                available_attrs = [attr for attr in dir(cuda_module) if not attr.startswith('_')]
                raise RuntimeError(f"æ— æ³•æ‰¾åˆ° {TEST_NN_MODEL_NAME} ç±»ã€‚å¯ç”¨å±æ€§: {available_attrs}")
            
            # è¿è¡Œæµ‹è¯•
            results = []
            for i, input_tensor in enumerate(input_tensors):
                try:
                    # ç¡®ä¿è¾“å…¥åœ¨CUDAä¸Š
                    input_tensor_cuda = []
                    for inp in input_tensor:
                        if not inp.is_cuda:
                            inp = inp.cuda()
                        input_tensor_cuda.append(inp.detach().clone())
                    
                    # æ‰§è¡ŒCUDAæ¨¡å‹
                    cuda_output = CudaModel()(*input_tensor_cuda)
                    results.append(cuda_output)
                    
                except Exception as e:
                    raise RuntimeError(f"æµ‹è¯•ç”¨ä¾‹ {i+1} æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            return results, "CUDAä»£ç æ‰§è¡ŒæˆåŠŸ"
            
    except Exception as e:
        raise RuntimeError(f"CUDAä»£ç æ‰§è¡Œå¤±è´¥: {str(e)}")

def enhanced_triton2cuda_with_monitoring(triton_code, file_name="unknown"):
    """å¢å¼ºç‰ˆtriton2cudaè°ƒç”¨ï¼ŒåŒ…å«è¯¦ç»†çš„APIè°ƒç”¨ç›‘æ§"""
    
    monitor = APICallMonitor()
    
    # 1. APIç«¯ç‚¹æ£€æŸ¥
    print("  æ­£åœ¨æ£€æŸ¥APIç«¯ç‚¹...")
    api_status = NetworkMonitor.check_api_endpoints()
    available_apis = [name for name, status in api_status.items() if status.get("available", False)]
    
    if not available_apis:
        error_msg = "æ‰€æœ‰APIç«¯ç‚¹éƒ½ä¸å¯ç”¨:\n"
        for name, status in api_status.items():
            error_msg += f"  - {name}: {status.get('error', 'ä¸å¯ç”¨')}\n"
        raise Exception(error_msg)
    
    print(f"  å¯ç”¨çš„API: {', '.join(available_apis)}")
    
    # 2. å°è¯•ä¸åŒçš„æ¨¡å‹å’Œpromptç­–ç•¥
    models_to_try = [
        ("deepseek-R1", "robust"),
        ("claude-sonnet-4", "full"),
        ("glm-4-plus", "function"),
        ("deepseek-R1", "simple")
    ]
    
    last_error = None
    attempt_details = []
    
    for model_type, prompt_type in models_to_try:
        # å¼€å§‹ç›‘æ§è¿™æ¬¡APIè°ƒç”¨
        monitor.start_call(model_type, prompt_type, len(triton_code))
        
        try:
            print(f"  å°è¯•ä½¿ç”¨æ¨¡å‹: {model_type} (prompt: {prompt_type})")
            
            # è®°å½•è¯·æ±‚è¯¦æƒ…
            monitor.record_request(
                model=model_type,
                prompt_strategy=prompt_type,
                input_code_length=len(triton_code),
                timestamp=datetime.now().isoformat()
            )
            
            # è°ƒç”¨åŸå§‹çš„triton2cudaå‡½æ•°ï¼Œä½†æˆ‘ä»¬éœ€è¦åŒ…è£…å®ƒæ¥æ•è·æ›´å¤šä¿¡æ¯
            cuda_code = monitored_triton2cuda_call(triton_code, model_type, prompt_type, monitor)
            
            # è®°å½•æˆåŠŸçš„å“åº”
            monitor.record_response(
                api_call_end=datetime.now().isoformat(),
                response_type="text",
                contains_python_code="```python" in cuda_code if cuda_code else False,
                contains_any_code="```" in cuda_code if cuda_code else False
            )
            
            attempt_details.append({
                "model": model_type,
                "prompt": prompt_type,
                "success": True,
                "duration": monitor.current_call["duration"] if monitor.current_call else 0,
                "code_length": len(cuda_code) if cuda_code else 0
            })
            
            # æ£€æŸ¥è¿”å›çš„ä»£ç æ˜¯å¦ä¸ºç©º
            if not cuda_code or not cuda_code.strip():
                print(f"    è­¦å‘Š: è¿”å›çš„ä»£ç ä¸ºç©ºï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹")
                last_error = f"æ¨¡å‹ {model_type} è¿”å›ç©ºä»£ç "
                monitor.record_error("EmptyResponse", last_error)
                monitor.end_call(False, cuda_code)
                continue
            
            print(f"    æˆåŠŸ! ä»£ç é•¿åº¦: {len(cuda_code)} å­—ç¬¦")
            
            # ç»“æŸæˆåŠŸçš„ç›‘æ§
            monitor.end_call(True, cuda_code)
            
            # ä¿å­˜æˆåŠŸçš„è½¬æ¢è®°å½•
            save_conversion_log_with_api_details(file_name, model_type, prompt_type, cuda_code, attempt_details, monitor)
            
            return cuda_code, attempt_details, monitor.call_history
            
        except Exception as e:
            error_msg = str(e)
            
            # åˆ†æé”™è¯¯ç±»å‹
            error_type = classify_api_error(error_msg)
            monitor.record_error(error_type, error_msg, traceback.format_exc())
            
            attempt_details.append({
                "model": model_type,
                "prompt": prompt_type,
                "success": False,
                "duration": time.time() - monitor.current_call["start_timestamp"] if monitor.current_call else 0,
                "error": error_msg,
                "error_type": error_type
            })
            
            print(f"    å¤±è´¥: {error_msg}")
            last_error = error_msg
            
            # ç»“æŸå¤±è´¥çš„ç›‘æ§
            monitor.end_call(False)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯APIè¿æ¥ç›¸å…³é”™è¯¯
            if error_type in ["NetworkError", "TimeoutError", "ConnectionError"]:
                print(f"    æ£€æµ‹åˆ°APIè¿æ¥é”™è¯¯ï¼Œç­‰å¾…5ç§’åé‡è¯•...")
                time.sleep(5)
            
            continue
    
    # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
    error_summary = f"æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†ã€‚æœ€åé”™è¯¯: {last_error}\n"
    error_summary += "å°è¯•è¯¦æƒ…:\n"
    for attempt in attempt_details:
        if attempt["success"]:
            error_summary += f"  âœ“ {attempt['model']}: æˆåŠŸ ({attempt['duration']:.2f}s)\n"
        else:
            error_summary += f"  âœ— {attempt['model']}: {attempt.get('error_type', 'Unknown')} - {attempt['error']}\n"
    
    # æ·»åŠ APIè°ƒç”¨ç»Ÿè®¡
    summary = monitor.get_summary()
    error_summary += f"\nAPIè°ƒç”¨ç»Ÿè®¡:\n"
    error_summary += f"  æ€»è°ƒç”¨æ¬¡æ•°: {summary['total_calls']}\n"
    error_summary += f"  æˆåŠŸæ¬¡æ•°: {summary['successful_calls']}\n"
    error_summary += f"  å¤±è´¥æ¬¡æ•°: {summary['failed_calls']}\n"
    error_summary += f"  æ€»è€—æ—¶: {summary['total_duration']:.2f}ç§’\n"
    error_summary += f"  å¹³å‡è€—æ—¶: {summary['average_duration']:.2f}ç§’\n"
    
    raise Exception(error_summary)

def monitored_triton2cuda_call(triton_code, model_type, prompt_type, monitor):
    """åŒ…è£…çš„triton2cudaè°ƒç”¨ï¼Œç”¨äºè®°å½•æ›´è¯¦ç»†çš„ä¿¡æ¯"""
    
    try:
        # è®°å½•æ›´å¤šè¯·æ±‚å‚æ•°
        monitor.record_request(
            api_call_start=datetime.now().isoformat(),
            temperature=0.1,
            max_tokens=4000
        )
        
        # è°ƒç”¨å®é™…çš„triton2cudaå‡½æ•°
        result = triton2cuda(triton_code, model_type=model_type, prompt_type=prompt_type)
        
        # è®°å½•å“åº”ä¿¡æ¯
        monitor.record_response(
            api_call_end=datetime.now().isoformat(),
            response_type="text",
            contains_python_code="```python" in result if result else False,
            contains_any_code="```" in result if result else False
        )
        
        return result
        
    except Exception as e:
        # è®°å½•APIè°ƒç”¨å¤±è´¥çš„è¯¦ç»†ä¿¡æ¯
        error_type = classify_api_error(str(e))
        monitor.record_error(error_type, str(e), traceback.format_exc())
        raise

def classify_api_error(error_message):
    """åˆ†ç±»APIé”™è¯¯ç±»å‹"""
    error_msg_lower = error_message.lower()
    
    # APIè¿æ¥è¶…æ—¶
    if any(keyword in error_msg_lower for keyword in ["timeout", "timed out"]):
        return "TimeoutError"
    
    # è¿æ¥é”™è¯¯
    if any(keyword in error_msg_lower for keyword in ["connection", "unreachable", "dns"]):
        return "ConnectionError"
    
    # APIè®¤è¯é”™è¯¯
    if any(keyword in error_msg_lower for keyword in ["unauthorized", "authentication", "api key", "forbidden"]):
        return "AuthenticationError"
    
    # é€Ÿç‡é™åˆ¶
    if any(keyword in error_msg_lower for keyword in ["rate limit", "quota", "too many requests"]):
        return "RateLimitError"
    
    # APIæœåŠ¡å™¨é”™è¯¯
    if any(keyword in error_msg_lower for keyword in ["500", "502", "503", "504", "server error"]):
        return "ServerError"
    
    # SSL/TLSé”™è¯¯
    if any(keyword in error_msg_lower for keyword in ["ssl", "certificate", "tls"]):
        return "SSLError"
    
    # ä¸€èˆ¬APIè¿æ¥é”™è¯¯
    if any(keyword in error_msg_lower for keyword in ["network", "socket", "http"]):
        return "NetworkError"
    
    return "UnknownError"

def save_conversion_log_with_api_details(file_name, model_type, prompt_type, cuda_code, attempts, monitor):
    """ä¿å­˜è½¬æ¢æ—¥å¿—ï¼ŒåŒ…å«APIè°ƒç”¨è¯¦æƒ…"""
    debug_dir = os.path.join(folder_path, "debug_output")
    os.makedirs(debug_dir, exist_ok=True)
    
    # ä¿å­˜è¯¦ç»†çš„è½¬æ¢æ—¥å¿—
    log_file = os.path.join(debug_dir, f"{file_name}_conversion_log.txt")
    with open(log_file, "w", encoding="utf-8") as f:
        f.write(f"è½¬æ¢æ—¥å¿— - {file_name}\n")
        f.write(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æˆåŠŸæ¨¡å‹: {model_type}\n")
        f.write(f"æˆåŠŸprompt: {prompt_type}\n")
        f.write(f"ç”Ÿæˆä»£ç é•¿åº¦: {len(cuda_code)}\n\n")
        
        # APIè°ƒç”¨ç»Ÿè®¡
        summary = monitor.get_summary()
        f.write("APIè°ƒç”¨ç»Ÿè®¡:\n")
        f.write(f"  æ€»è°ƒç”¨æ¬¡æ•°: {summary['total_calls']}\n")
        f.write(f"  æˆåŠŸæ¬¡æ•°: {summary['successful_calls']}\n")
        f.write(f"  å¤±è´¥æ¬¡æ•°: {summary['failed_calls']}\n")
        f.write(f"  æ€»è€—æ—¶: {summary['total_duration']:.2f}ç§’\n")
        f.write(f"  å¹³å‡è€—æ—¶: {summary['average_duration']:.2f}ç§’\n")
        f.write(f"  æˆåŠŸç‡: {summary['success_rate']*100:.1f}%\n\n")
        
        f.write("æ‰€æœ‰å°è¯•:\n")
        for i, attempt in enumerate(attempts, 1):
            f.write(f"  {i}. {attempt['model']} ({attempt['prompt']}): ")
            if attempt["success"]:
                f.write(f"æˆåŠŸ ({attempt['duration']:.2f}s)\n")
            else:
                error_type = attempt.get("error_type", "Unknown")
                f.write(f"å¤±è´¥ - {error_type}: {attempt['error']}\n")
    
    # ä¿å­˜è¯¦ç»†çš„APIè°ƒç”¨å†å²ï¼ˆJSONæ ¼å¼ï¼‰
    api_log_file = os.path.join(debug_dir, f"{file_name}_api_calls.json")
    with open(api_log_file, "w", encoding="utf-8") as f:
        json.dump(monitor.call_history, f, indent=2, default=str, ensure_ascii=False)
    
    print(f"  APIè°ƒç”¨è¯¦æƒ…å·²ä¿å­˜åˆ°: {api_log_file}")

def classify_error_type(error_message):
    """æ ¹æ®é”™è¯¯æ¶ˆæ¯åˆ†ç±»é”™è¯¯ç±»å‹"""
    error_msg_lower = error_message.lower()
    
    # APIè¿æ¥ç›¸å…³é”™è¯¯
    network_keywords = ["timeout", "connection", "network", "dns", "ssl", "certificate", "unreachable"]
    if any(keyword in error_msg_lower for keyword in network_keywords):
        return ErrorType.NETWORK_ERROR
    
    # APIç›¸å…³é”™è¯¯
    api_keywords = ["api", "authentication", "unauthorized", "forbidden", "rate limit", "quota"]
    if any(keyword in error_msg_lower for keyword in api_keywords):
        return ErrorType.API_ERROR
    
    # ç¼–è¯‘é”™è¯¯
    compilation_keywords = ["syntax error", "compilation error", "compile", "nvcc", "undefined", "redefinition"]
    if any(keyword in error_msg_lower for keyword in compilation_keywords):
        return ErrorType.COMPILATION_ERROR
    
    # è¿è¡Œæ—¶é”™è¯¯
    runtime_keywords = ["runtime error", "execution", "cuda", "kernel", "memory", "device"]
    if any(keyword in error_msg_lower for keyword in runtime_keywords):
        return ErrorType.RUNTIME_ERROR
    
    # é»˜è®¤ä¸ºè¿è¡Œæ—¶é”™è¯¯
    return ErrorType.RUNTIME_ERROR

def eval_single_file_enhanced(file_name: str, verbose: bool = False) -> TestResult:
    """å¢å¼ºç‰ˆå•æ–‡ä»¶è¯„æµ‹"""
    print(f"\n=== è¯„æµ‹ {file_name} ===")
    result = TestResult(file_name)
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šè¯»å–Tritonä»£ç 
        triton_file_path = os.path.join("data", "triton", "local_test_list", file_name)
        if not os.path.exists(triton_file_path):
            result.set_error(ErrorType.RUNTIME_ERROR, f"æ— æ³•æ‰¾åˆ°Tritonæ–‡ä»¶: {triton_file_path}")
            return result
        
        with open(triton_file_path, "r") as f:
            triton_code = f.read()
        
        # ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸ºCUDAä»£ç ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆï¼‰
        print("  æ­£åœ¨è½¬æ¢Tritonä»£ç ä¸ºCUDAä»£ç ...")
        try:
            cuda_code, conversion_attempts, api_call_history = enhanced_triton2cuda_with_monitoring(triton_code, file_name)
            result.cuda_code = cuda_code
            
            # è®°å½•è½¬æ¢è¯¦æƒ…å’ŒAPIè°ƒç”¨å†å²
            result.conversion_details = conversion_attempts
            result.api_call_history = api_call_history
            
            if not cuda_code.strip():
                result.set_error(ErrorType.RUNTIME_ERROR, "è½¬æ¢åçš„ä»£ç ä¸ºç©º")
                return result
                
            print(f"  è½¬æ¢æˆåŠŸï¼Œä»£ç é•¿åº¦: {len(cuda_code)} å­—ç¬¦")
            
        except Exception as e:
            error_type = classify_error_type(str(e))
            result.set_error(error_type, f"CUDAä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}")
            if verbose:
                result.error_message += f"\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
            # ä¿å­˜è°ƒè¯•ä¿¡æ¯
            save_debug_info(file_name, result.cuda_code, f"CUDAä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}\n\n{traceback.format_exc()}")
            return result
        
        # ç¬¬ä¸‰æ­¥ï¼šç¼–è¯‘æ£€æŸ¥
        print("  æ­£åœ¨æ£€æŸ¥CUDAä»£ç ç¼–è¯‘...")
        compilation_success, compilation_message = check_cuda_compilation(cuda_code, file_name)
        result.set_compilation_result(compilation_success, compilation_message)
        
        if not compilation_success:
            result.set_error(ErrorType.COMPILATION_ERROR, compilation_message)
            result.calculate_total_score()
            return result
        
        print(f"  ç¼–è¯‘æ£€æŸ¥é€šè¿‡: {compilation_message}")
        
        # ç¬¬å››æ­¥ï¼šè·å–å‚è€ƒæ¨¡å‹å’Œè¾“å…¥æ•°æ®
        try:
            RefModel, input_tensors = get_reference_model_and_inputs(file_name)
            print(f"  å‡†å¤‡äº† {len(input_tensors)} ç»„æµ‹è¯•æ•°æ®")
        except Exception as e:
            result.set_error(ErrorType.RUNTIME_ERROR, f"è·å–å‚è€ƒæ¨¡å‹å¤±è´¥: {str(e)}")
            return result
        
        # ç¬¬äº”æ­¥ï¼šè¿è¡ŒCUDAä»£ç 
        print("  æ­£åœ¨è¿è¡ŒCUDAä»£ç æµ‹è¯•...")
        try:
            cuda_results, run_message = run_cuda_code_test(cuda_code, input_tensors, file_name)
            print(f"  CUDAä»£ç æ‰§è¡ŒæˆåŠŸ")
        except Exception as e:
            result.set_error(ErrorType.RUNTIME_ERROR, f"CUDAä»£ç æ‰§è¡Œå¤±è´¥: {str(e)}")
            if verbose:
                result.error_message += f"\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
            result.calculate_total_score()
            return result
        
        # ç¬¬å…­æ­¥ï¼šè®¡ç®—å‚è€ƒç»“æœå¹¶æ¯”è¾ƒ
        print("  æ­£åœ¨æ¯”è¾ƒç»“æœ...")
        passed_tests = 0
        total_tests = len(input_tensors)
        
        for i, (input_tensor, cuda_output) in enumerate(zip(input_tensors, cuda_results)):
            try:
                # ç¡®ä¿è¾“å…¥åœ¨CUDAä¸Š
                input_tensor_cuda = []
                for inp in input_tensor:
                    if not inp.is_cuda:
                        inp = inp.cuda()
                    input_tensor_cuda.append(inp.detach().clone())
                
                # è®¡ç®—å‚è€ƒè¾“å‡º
                ref_output = RefModel()(*input_tensor_cuda)
                
                # æ¯”è¾ƒç»“æœ
                if torch.allclose(cuda_output, ref_output, atol=1e-3, rtol=1e-3):
                    print(f"  æµ‹è¯• {i+1}: é€šè¿‡")
                    passed_tests += 1
                    result.test_details.append(f"æµ‹è¯• {i+1}: é€šè¿‡")
                else:
                    max_diff = torch.max(torch.abs(cuda_output - ref_output)).item()
                    error_msg = f"æµ‹è¯• {i+1}: å¤±è´¥ - è¾“å‡ºä¸åŒ¹é…ï¼Œæœ€å¤§å·®å¼‚: {max_diff:.6f}"
                    print(f"  {error_msg}")
                    result.test_details.append(error_msg)
                    
                    if verbose:
                        print(f"    å‚è€ƒè¾“å‡ºå½¢çŠ¶: {ref_output.shape}, ç»Ÿè®¡: min={ref_output.min().item():.6f}, max={ref_output.max().item():.6f}")
                        print(f"    CUDAè¾“å‡ºå½¢çŠ¶: {cuda_output.shape}, ç»Ÿè®¡: min={cuda_output.min().item():.6f}, max={cuda_output.max().item():.6f}")
                        
            except Exception as e:
                error_msg = f"æµ‹è¯• {i+1}: å¤±è´¥ - æ¯”è¾ƒè¿‡ç¨‹å¼‚å¸¸: {str(e)}"
                print(f"  {error_msg}")
                result.test_details.append(error_msg)
                if verbose:
                    print(f"    è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # è®¾ç½®å‡†ç¡®æ€§åˆ†æ•°
        result.set_accuracy_result(passed_tests, total_tests)
        
        if passed_tests == total_tests:
            print(f"  æ‰€æœ‰æµ‹è¯•é€šè¿‡: {passed_tests}/{total_tests}")
            result.error_type = ErrorType.SUCCESS
        else:
            print(f"  éƒ¨åˆ†æµ‹è¯•å¤±è´¥: {passed_tests}/{total_tests}")
            result.set_error(ErrorType.OUTPUT_MISMATCH_ERROR, f"ç»“æœä¸åŒ¹é…: {passed_tests}/{total_tests} æµ‹è¯•é€šè¿‡")
        
        result.calculate_total_score()
        return result
        
    except Exception as e:
        error_type = classify_error_type(str(e))
        result.set_error(error_type, f"è¯„æµ‹è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        if verbose:
            result.error_message += f"\nè¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}"
        result.calculate_total_score()
        return result

def save_debug_info(file_name, cuda_code, error_info):
    """ä¿å­˜è°ƒè¯•ä¿¡æ¯åˆ°debug_outputæ–‡ä»¶å¤¹"""
    debug_dir = os.path.join(folder_path, "debug_output")
    os.makedirs(debug_dir, exist_ok=True)
    
    # ä¿å­˜è½¬æ¢åçš„CUDAä»£ç 
    cuda_file = os.path.join(debug_dir, f"{file_name}_cuda.py")
    with open(cuda_file, "w") as f:
        f.write(cuda_code)
    
    # ä¿å­˜é”™è¯¯ä¿¡æ¯
    error_file = os.path.join(debug_dir, f"{file_name}_error.txt")
    with open(error_file, "w") as f:
        f.write(error_info)
    
    print(f"  è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜åˆ°: {debug_dir}/")

def save_result_report(results: List[TestResult], output_file: str = "evaluation_report.txt"):
    """ä¿å­˜è¯¦ç»†çš„è¯„æµ‹æŠ¥å‘Šåˆ°debug_outputæ–‡ä»¶å¤¹"""
    # ç¡®ä¿debug_outputæ–‡ä»¶å¤¹å­˜åœ¨
    debug_dir = os.path.join(folder_path, "debug_output")
    os.makedirs(debug_dir, exist_ok=True)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå®Œæ•´è·¯å¾„ï¼Œåˆ™ä¿å­˜åˆ°debug_outputæ–‡ä»¶å¤¹
    if not os.path.isabs(output_file):
        output_file = os.path.join(debug_dir, output_file)
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("=" * 60 + "\n")
        f.write("Tritonåˆ°CUDAè½¬æ¢è¯„æµ‹æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        # æ€»ä½“ç»Ÿè®¡
        total_files = len(results)
        successful_files = sum(1 for r in results if r.error_type == ErrorType.SUCCESS)
        total_score = sum(r.total_score for r in results)
        max_score = total_files * 10
        
        f.write(f"æ€»ä½“ç»Ÿè®¡:\n")
        f.write(f"  æµ‹è¯•æ–‡ä»¶æ•°: {total_files}\n")
        f.write(f"  æˆåŠŸæ–‡ä»¶æ•°: {successful_files}\n")
        f.write(f"  æ€»åˆ†: {total_score}/{max_score}\n")
        f.write(f"  å¹³å‡åˆ†: {total_score/total_files:.2f}/10\n")
        f.write(f"  æˆåŠŸç‡: {successful_files/total_files*100:.1f}%\n\n")
        
        # é”™è¯¯ç±»å‹ç»Ÿè®¡
        error_stats = {}
        for result in results:
            error_type = result.error_type.value
            error_stats[error_type] = error_stats.get(error_type, 0) + 1
        
        f.write(f"é”™è¯¯ç±»å‹ç»Ÿè®¡:\n")
        for error_type, count in error_stats.items():
            f.write(f"  {error_type}: {count}\n")
        f.write("\n")
        
        # APIè°ƒç”¨ç»Ÿè®¡æ±‡æ€»
        total_api_calls = 0
        total_api_duration = 0
        successful_api_calls = 0
        api_error_types = {}
        
        for result in results:
            if hasattr(result, 'api_call_history') and result.api_call_history:
                for call in result.api_call_history:
                    total_api_calls += 1
                    total_api_duration += call.get('duration', 0)
                    if call.get('success', False):
                        successful_api_calls += 1
                    else:
                        error_type = call.get('error_details', {}).get('error_type', 'Unknown')
                        api_error_types[error_type] = api_error_types.get(error_type, 0) + 1
        
        f.write(f"APIè°ƒç”¨ç»Ÿè®¡æ±‡æ€»:\n")
        f.write(f"  æ€»APIè°ƒç”¨æ¬¡æ•°: {total_api_calls}\n")
        f.write(f"  æˆåŠŸAPIè°ƒç”¨: {successful_api_calls}\n")
        f.write(f"  å¤±è´¥APIè°ƒç”¨: {total_api_calls - successful_api_calls}\n")
        f.write(f"  APIæˆåŠŸç‡: {successful_api_calls/total_api_calls*100:.1f}%\n" if total_api_calls > 0 else "  APIæˆåŠŸç‡: N/A\n")
        f.write(f"  æ€»APIè€—æ—¶: {total_api_duration:.2f}ç§’\n")
        f.write(f"  å¹³å‡APIè€—æ—¶: {total_api_duration/total_api_calls:.2f}ç§’\n" if total_api_calls > 0 else "  å¹³å‡APIè€—æ—¶: N/A\n")
        
        if api_error_types:
            f.write(f"  APIé”™è¯¯ç±»å‹åˆ†å¸ƒ:\n")
            for error_type, count in api_error_types.items():
                f.write(f"    {error_type}: {count}\n")
        f.write("\n")
        
        # æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»æ˜¾ç¤ºæ–‡ä»¶
        f.write("æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»:\n")
        for error_type in ErrorType:
            files_with_error = [r for r in results if r.error_type == error_type]
            if files_with_error:
                f.write(f"  {error_type.value} ({len(files_with_error)} ä¸ªæ–‡ä»¶):\n")
                for result in files_with_error:
                    f.write(f"    - {result.file_name}: {result.total_score}/10\n")
        f.write("\n")
        
        # ç¼–è¯‘å’Œå‡†ç¡®æ€§ç»Ÿè®¡
        compilation_success = sum(1 for r in results if r.compilation_score > 0)
        accuracy_success = sum(1 for r in results if r.accuracy_score > 0)
        
        f.write(f"åˆ†é¡¹ç»Ÿè®¡:\n")
        f.write(f"  ç¼–è¯‘é€šè¿‡: {compilation_success}/{total_files} ({compilation_success/total_files*100:.1f}%)\n")
        f.write(f"  æœ‰å‡†ç¡®æ€§åˆ†æ•°: {accuracy_success}/{total_files} ({accuracy_success/total_files*100:.1f}%)\n\n")
        
        # APIè¿æ¥å’Œè°ƒç”¨ç»Ÿè®¡
        network_errors = sum(1 for r in results if r.error_type == ErrorType.NETWORK_ERROR)
        api_errors = sum(1 for r in results if r.error_type == ErrorType.API_ERROR)
        
        f.write(f"APIç›¸å…³ç»Ÿè®¡:\n")
        f.write(f"  APIè¿æ¥é”™è¯¯: {network_errors}/{total_files} ({network_errors/total_files*100:.1f}%)\n")
        f.write(f"  APIè°ƒç”¨é”™è¯¯: {api_errors}/{total_files} ({api_errors/total_files*100:.1f}%)\n\n")
        
        # è¯¦ç»†ç»“æœ
        f.write("è¯¦ç»†ç»“æœ:\n")
        f.write("-" * 60 + "\n")
        
        for result in results:
            f.write(f"\næ–‡ä»¶: {result.file_name}\n")
            f.write(f"æ€»åˆ†: {result.total_score}/10 (ç¼–è¯‘: {result.compilation_score}/1, å‡†ç¡®æ€§: {result.accuracy_score}/9)\n")
            f.write(f"é”™è¯¯ç±»å‹: {result.error_type.value}\n")
            
            # APIè°ƒç”¨è¯¦æƒ…
            if hasattr(result, 'api_call_history') and result.api_call_history:
                f.write("APIè°ƒç”¨è¯¦æƒ…:\n")
                for i, call in enumerate(result.api_call_history, 1):
                    status = "æˆåŠŸ" if call.get('success', False) else "å¤±è´¥"
                    duration = call.get('duration', 0)
                    model = call.get('model_type', 'Unknown')
                    f.write(f"  è°ƒç”¨{i}: {model} - {status} ({duration:.2f}s)\n")
                    
                    if not call.get('success', False) and call.get('error_details'):
                        error_info = call['error_details']
                        f.write(f"    é”™è¯¯ç±»å‹: {error_info.get('error_type', 'Unknown')}\n")
                        f.write(f"    é”™è¯¯ä¿¡æ¯: {error_info.get('error_message', '')[:100]}...\n")
            
            # è½¬æ¢è¯¦æƒ…
            if hasattr(result, 'conversion_details') and result.conversion_details:
                f.write("è½¬æ¢å°è¯•è¯¦æƒ…:\n")
                for i, attempt in enumerate(result.conversion_details, 1):
                    if attempt["success"]:
                        f.write(f"  {i}. {attempt['model']} ({attempt['prompt']}): æˆåŠŸ ({attempt['duration']:.2f}s, {attempt['code_length']} å­—ç¬¦)\n")
                    else:
                        error_type = attempt.get('error_type', 'Unknown')
                        f.write(f"  {i}. {attempt['model']} ({attempt['prompt']}): å¤±è´¥ ({attempt['duration']:.2f}s) - {error_type}\n")
            
            if result.error_message:
                f.write(f"é”™è¯¯ä¿¡æ¯: {result.error_message}\n")
            
            if result.compilation_output:
                f.write(f"ç¼–è¯‘è¾“å‡º: {result.compilation_output}\n")
            
            if result.test_details:
                f.write("æµ‹è¯•è¯¦æƒ…:\n")
                for detail in result.test_details:
                    f.write(f"  {detail}\n")
            
            # ä¿å­˜è½¬æ¢åçš„CUDAä»£ç ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if result.cuda_code:
                cuda_file = os.path.join(debug_dir, f"{result.file_name}_cuda.py")
                with open(cuda_file, "w") as cuda_f:
                    cuda_f.write(result.cuda_code)
                f.write(f"CUDAä»£ç å·²ä¿å­˜åˆ°: {cuda_file}\n")
            
            # ä¿å­˜APIè°ƒç”¨è¯¦æƒ…ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if hasattr(result, 'api_call_history') and result.api_call_history:
                api_file = os.path.join(debug_dir, f"{result.file_name}_api_details.json")
                with open(api_file, "w", encoding="utf-8") as api_f:
                    json.dump(result.api_call_history, api_f, indent=2, default=str, ensure_ascii=False)
                f.write(f"APIè°ƒç”¨è¯¦æƒ…å·²ä¿å­˜åˆ°: {api_file}\n")
            
            f.write("-" * 40 + "\n")
    
    print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

def cleanup():
    """æ¸…ç†å‡½æ•°"""
    os.chdir(original_cwd)

def eval_all_files_enhanced(verbose: bool = False) -> List[TestResult]:
    """å¢å¼ºç‰ˆæ‰¹é‡è¯„æµ‹æ‰€æœ‰æ–‡ä»¶"""
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # è·å–æ‰€æœ‰tritonæ–‡ä»¶
    test_dir = os.path.join("data", "triton", "local_test_list")
    
    if not os.path.exists(test_dir):
        print("âŒ æ— æ³•æ‰¾åˆ°æµ‹è¯•ç›®å½•ï¼Œç»ˆæ­¢è¯„æµ‹")
        return []
    
    try:
        triton_files = [f for f in os.listdir(test_dir) if f.endswith('.py')]
        triton_files.sort()  # æŒ‰å­—æ¯é¡ºåºæ’åº
    except Exception as e:
        print(f"âŒ æ— æ³•åˆ—å‡ºæµ‹è¯•ç›®å½•å†…å®¹: {e}")
        return []
    
    print(f"æ‰¾åˆ° {len(triton_files)} ä¸ªtritonæ–‡ä»¶éœ€è¦è¯„æµ‹")
    
    results = []
    
    for i, file_name in enumerate(triton_files):
        print(f"\nè¿›åº¦: {i+1}/{len(triton_files)}")
        result = eval_single_file_enhanced(file_name, verbose)
        results.append(result)
        
        # æ˜¾ç¤ºç®€è¦ç»“æœ
        print(f"ç»“æœ: {result.get_summary()}")
        if result.error_type != ErrorType.SUCCESS:
            print(f"é”™è¯¯ç±»å‹: {result.error_type.value}")
            if result.error_message:
                print(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
    
    return results

def print_final_summary(results: List[TestResult]):
    """æ‰“å°æœ€ç»ˆæ±‡æ€»"""
    print(f"\n{'='*60}")
    print("æœ€ç»ˆè¯„æµ‹ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    
    # æ€»ä½“ç»Ÿè®¡
    total_files = len(results)
    successful_files = sum(1 for r in results if r.error_type == ErrorType.SUCCESS)
    total_score = sum(r.total_score for r in results)
    max_score = total_files * 10
    
    print(f"æ€»ä½“ç»Ÿè®¡:")
    print(f"  æµ‹è¯•æ–‡ä»¶æ•°: {total_files}")
    print(f"  æˆåŠŸæ–‡ä»¶æ•°: {successful_files}")
    print(f"  æ€»åˆ†: {total_score}/{max_score}")
    print(f"  å¹³å‡åˆ†: {total_score/total_files:.2f}/10")
    print(f"  æˆåŠŸç‡: {successful_files/total_files*100:.1f}%")
    
    # é”™è¯¯ç±»å‹ç»Ÿè®¡
    error_stats = {}
    for result in results:
        error_type = result.error_type.value
        error_stats[error_type] = error_stats.get(error_type, 0) + 1
    
    print(f"\né”™è¯¯ç±»å‹ç»Ÿè®¡:")
    for error_type, count in error_stats.items():
        print(f"  {error_type}: {count}")
    
    # ç‰¹åˆ«å…³æ³¨APIç›¸å…³é”™è¯¯
    network_errors = error_stats.get("NetworkError", 0)
    api_errors = error_stats.get("APIError", 0)
    
    if network_errors > 0 or api_errors > 0:
        print(f"\nâš ï¸  APIç›¸å…³é—®é¢˜:")
        if network_errors > 0:
            print(f"  APIè¿æ¥é”™è¯¯: {network_errors} ä¸ªæ–‡ä»¶")
        if api_errors > 0:
            print(f"  APIè°ƒç”¨é”™è¯¯: {api_errors} ä¸ªæ–‡ä»¶")
        print(f"  å»ºè®®: æ£€æŸ¥APIé…ç½®å’Œç«¯ç‚¹å¯ç”¨æ€§")
    
    # æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»æ˜¾ç¤ºæ–‡ä»¶
    print(f"\næŒ‰é”™è¯¯ç±»å‹åˆ†ç±»:")
    for error_type in ErrorType:
        files_with_error = [r for r in results if r.error_type == error_type]
        if files_with_error:
            print(f"  {error_type.value} ({len(files_with_error)} ä¸ªæ–‡ä»¶):")
            for result in files_with_error:
                print(f"    - {result.file_name}: {result.total_score}/10")
    
    # ç¼–è¯‘å’Œå‡†ç¡®æ€§ç»Ÿè®¡
    compilation_success = sum(1 for r in results if r.compilation_score > 0)
    accuracy_success = sum(1 for r in results if r.accuracy_score > 0)
    
    print(f"\nåˆ†é¡¹ç»Ÿè®¡:")
    print(f"  ç¼–è¯‘é€šè¿‡: {compilation_success}/{total_files} ({compilation_success/total_files*100:.1f}%)")
    print(f"  æœ‰å‡†ç¡®æ€§åˆ†æ•°: {accuracy_success}/{total_files} ({accuracy_success/total_files*100:.1f}%)")

# æ–°å¢ï¼šAPIè¿é€šæ€§æµ‹è¯•å‡½æ•°
def test_api_connectivity():
    """æµ‹è¯•APIç«¯ç‚¹å¯ç”¨æ€§"""
    print("=== APIè¿é€šæ€§æµ‹è¯• ===")
    
    # APIç«¯ç‚¹æµ‹è¯•
    print("APIç«¯ç‚¹æµ‹è¯•:")
    api_status = NetworkMonitor.check_api_endpoints()
    
    for name, status in api_status.items():
        if status.get("available", False):
            response_time = status.get("response_time", 0)
            print(f"  {name}: âœ“ å¯ç”¨ (å“åº”æ—¶é—´: {response_time:.2f}s)")
        else:
            error = status.get("error", "ä¸å¯ç”¨")
            print(f"  {name}: âœ— ä¸å¯ç”¨ ({error})")
    
    available_apis = [name for name, status in api_status.items() if status.get("available", False)]
    
    if available_apis:
        print(f"\nå¯ç”¨API: {', '.join(available_apis)}")
        return True
    else:
        print("\nâŒ æ‰€æœ‰APIéƒ½ä¸å¯ç”¨")
        return False

if __name__ == "__main__":
    try:
        parser = argparse.ArgumentParser(description="Tritonåˆ°CUDAè½¬æ¢è¯„æµ‹ç³»ç»Ÿ")
        parser.add_argument("--file", type=str, help="è¯„æµ‹å•ä¸ªæ–‡ä»¶")
        parser.add_argument("--all", action="store_true", help="è¯„æµ‹æ‰€æœ‰æ–‡ä»¶")
        parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
        parser.add_argument("--network", action="store_true", help="æµ‹è¯•APIç«¯ç‚¹å¯ç”¨æ€§")
        parser.add_argument("--output", type=str, default="evaluation_report.txt", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶åï¼ˆå°†ä¿å­˜åˆ°debug_outputæ–‡ä»¶å¤¹ï¼‰")
        
        args = parser.parse_args()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®‰è£…requestsåº“
        try:
            import requests
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…requestsåº“")
            print("è¯·è¿è¡Œ: pip install requests")
            exit(1)
        
        if args.network:
            # APIè¿é€šæ€§æµ‹è¯•
            success = test_api_connectivity()
            if not success:
                print("\nå»ºè®®:")
                print("1. éªŒè¯APIå¯†é’¥é…ç½®")
                print("2. ç¡®è®¤é˜²ç«å¢™è®¾ç½®")
                print("3. å°è¯•ä½¿ç”¨VPNæˆ–ä»£ç†")
                print("4. æ£€æŸ¥APIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            exit(0)
        
        elif args.file:
            # å•æ–‡ä»¶è¯„æµ‹
            result = eval_single_file_enhanced(args.file, args.verbose)
            print(f"\n{result.get_summary()}")
            
            # æ˜¾ç¤ºAPIç›¸å…³æç¤º
            if result.error_type in [ErrorType.NETWORK_ERROR, ErrorType.API_ERROR]:
                print("\nğŸ’¡ APIç›¸å…³é”™è¯¯è§£å†³å»ºè®®:")
                print("1. è¿è¡Œ --network å‚æ•°æµ‹è¯•APIç«¯ç‚¹å¯ç”¨æ€§")
                print("2. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®")
                print("3. ç¡®è®¤APIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
                print("4. å°è¯•åˆ‡æ¢ç½‘ç»œç¯å¢ƒæˆ–ä½¿ç”¨ä»£ç†")
            
            save_result_report([result], f"{args.file}_evaluation_report.txt")
            
        elif args.all:
            # æ‰¹é‡è¯„æµ‹
            results = eval_all_files_enhanced(args.verbose)
            print_final_summary(results)
            save_result_report(results, args.output)
            
        else:
            # é»˜è®¤æµ‹è¯•flashatt.py
            result = eval_single_file_enhanced("flashatt.py", verbose=True)
            print(f"\n{result.get_summary()}")
            
            # æ˜¾ç¤ºAPIç›¸å…³æç¤º
            if result.error_type in [ErrorType.NETWORK_ERROR, ErrorType.API_ERROR]:
                print("\nğŸ’¡ APIç›¸å…³é”™è¯¯è§£å†³å»ºè®®:")
                print("1. è¿è¡Œ --network å‚æ•°æµ‹è¯•APIç«¯ç‚¹å¯ç”¨æ€§")
                print("2. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®")
                print("3. ç¡®è®¤APIæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
                print("4. å°è¯•åˆ‡æ¢ç½‘ç»œç¯å¢ƒæˆ–ä½¿ç”¨ä»£ç†")
            
            save_result_report([result], "flashatt_evaluation_report.txt")
        
    except Exception as e:
        print(f"è¯„æµ‹è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    finally:
        cleanup() 